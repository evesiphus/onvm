{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce3a2b4",
   "metadata": {},
   "source": [
    "# Combine header for pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5115c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b667caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vnfs=['bridge','firewall','ndpi_stats',\"nf_router\",'payload_scan','rx','tx']\n",
    "folders=[\"const-1\",\"const-2\",\"const-3\",\"const-4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d775e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccc08b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridge-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\bridge-pcm_processed.csv\n",
      "firewall-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\firewall-pcm_processed.csv\n",
      "ndpi_stats-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\ndpi_stats-pcm_processed.csv\n",
      "nf_router-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\nf_router-pcm_processed.csv\n",
      "payload_scan-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\payload_scan-pcm_processed.csv\n",
      "rx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\rx-pcm_processed.csv\n",
      "tx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-1\\tx-pcm_processed.csv\n",
      "bridge-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\bridge-pcm_processed.csv\n",
      "firewall-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\firewall-pcm_processed.csv\n",
      "ndpi_stats-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\ndpi_stats-pcm_processed.csv\n",
      "nf_router-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\nf_router-pcm_processed.csv\n",
      "payload_scan-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\payload_scan-pcm_processed.csv\n",
      "rx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\rx-pcm_processed.csv\n",
      "tx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\tx-pcm_processed.csv\n",
      "bridge-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\bridge-pcm_processed.csv\n",
      "firewall-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\firewall-pcm_processed.csv\n",
      "ndpi_stats-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\ndpi_stats-pcm_processed.csv\n",
      "nf_router-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\nf_router-pcm_processed.csv\n",
      "payload_scan-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\payload_scan-pcm_processed.csv\n",
      "rx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\rx-pcm_processed.csv\n",
      "tx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\tx-pcm_processed.csv\n",
      "bridge-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\bridge-pcm_processed.csv\n",
      "firewall-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\firewall-pcm_processed.csv\n",
      "ndpi_stats-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\ndpi_stats-pcm_processed.csv\n",
      "nf_router-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\nf_router-pcm_processed.csv\n",
      "payload_scan-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\payload_scan-pcm_processed.csv\n",
      "rx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\rx-pcm_processed.csv\n",
      "tx-pcm\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\tx-pcm_processed.csv\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    for i in vnfs:\n",
    "        exp_ls = f'{i}-pcm'\n",
    "        input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}.csv'\n",
    "        output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{i}-pcm_processed.csv'\n",
    "        combine_csv_headers(input_file_path, output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ecffa",
   "metadata": {},
   "source": [
    "# pcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53d43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ls = f'pcm-pcie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61121f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-pcie_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def reshape_and_remove_columns(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Extract and modify the header\n",
    "    original_header = rows[0]\n",
    "    new_header = [f'skt-0_{h}-total' for h in original_header]+ [f'skt-0_{h}-miss' for h in original_header]  + [f'skt-0_{h}-hit' for h in original_header]+[f'skt-1_{h}-total' for h in original_header]+ [f'skt-1_{h}-miss' for h in original_header]+ [f'skt-1_{h}-hit' for h in original_header]\n",
    "\n",
    "    # Process the data rows\n",
    "    reshaped_rows = []\n",
    "    for i in range(1, len(rows), 7):  # Skip every third row (the repeated header)\n",
    "        row_0 = rows[i]\n",
    "        if i + 1 < len(rows):  # Check if the next row exists\n",
    "            row_1 = rows[i+1]\n",
    "            row_2 = rows[i+2]\n",
    "            row_3 = rows[i+3]\n",
    "            row_4 = rows[i+4]\n",
    "            row_5 = rows[i+5]\n",
    "            combined_row = row_0 + row_1 + row_2 + row_3 + row_4 + row_5\n",
    "            reshaped_rows.append(combined_row)\n",
    "\n",
    "    # Remove columns: Find the index of the columns to be removed\n",
    "    indices_to_remove = [new_header.index('skt-0_Skt-total'), new_header.index('skt-1_Skt-total'),\n",
    "                        new_header.index('skt-0_Skt-miss'), new_header.index('skt-1_Skt-miss'),\n",
    "                        new_header.index('skt-0_Skt-hit'), new_header.index('skt-1_Skt-hit'),]\n",
    "\n",
    "    # Remove columns: Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(new_header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row) if i not in indices_to_remove] for row in reshaped_rows]\n",
    "\n",
    "    # Write the processed data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header) \n",
    "        writer.writerows(updated_rows) \n",
    "    return output_file\n",
    "\n",
    "# Predefined file paths\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = reshape_and_remove_columns(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4868d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-pcie_processed.csv\n",
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-pcie_processed.csv\n",
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-pcie_processed.csv\n",
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-pcie_processed.csv\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'pcm-pcie'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    reshape_and_remove_columns(input_file_path, output_file_path)\n",
    "    print(f\"Processed file saved as: {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16a4068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_numeric_columns(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.extract(r'(\\d+)', expand=False)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def clean_csv_file(input_csv_path, output_csv_path):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    cleaned_df = clean_numeric_columns(df)\n",
    "    cleaned_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Predefined file paths\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = clean_csv_file(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a35a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'pcm-pcie'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    clean_csv_file(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d937ad",
   "metadata": {},
   "source": [
    "# memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93a447d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_file：..\\data\\pcm\\const_input\\const-1\\pcm-memory_processed.csv\n",
      "Processed file saved as: None\n"
     ]
    }
   ],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n",
    "\n",
    "# Predefined file paths\n",
    "exp_ls=f'pcm-memory'\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = combine_csv_headers(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31163f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_file：..\\data\\pcm\\const_input\\const-1\\pcm-memory_processed.csv\n",
      "new_file：..\\data\\pcm\\const_input\\const-2\\pcm-memory_processed.csv\n",
      "new_file：..\\data\\pcm\\const_input\\const-3\\pcm-memory_processed.csv\n",
      "new_file：..\\data\\pcm\\const_input\\const-4\\pcm-memory_processed.csv\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'pcm-memory'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea52aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: ..\\data\\pcm\\const_input\\const-1\\pcm-memory_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def remove_columns_and_empty_values(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"CSV file is empty\")\n",
    "\n",
    "    # Find the index of the columns to be removed\n",
    "    header = rows[0]\n",
    "    num_columns = len(header)\n",
    "    indices_to_remove = [i for i, h in enumerate(header) if h.lower() in ['-date', '-time'] or all((len(row) > i and row[i] == '') for row in rows[1:])]\n",
    "\n",
    "    # Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row[:num_columns]) if i not in indices_to_remove] for row in rows[1:]]\n",
    "\n",
    "    # Write the updated data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header)  # Write the updated header\n",
    "        writer.writerows(updated_rows)  # Write the updated data rows\n",
    "\n",
    "    return output_file\n",
    "\n",
    "# Predefined file paths\n",
    "exp_ls=f'pcm-memory'\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\{exp_ls}_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = remove_columns_and_empty_values(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef704a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'pcm-memory'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    remove_columns_and_empty_values(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee86f50",
   "metadata": {},
   "source": [
    "# extract traffic and latency information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84bc9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def latency_pre(input_csv, output_csv, delimiter=' '):\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv, delimiter=delimiter, header=None)\n",
    "    df.drop(columns=df.columns[0], inplace=True)\n",
    "   # df.to_csv(output_csv, index=False, header=False, sep=delimiter)\n",
    "    df.to_csv(output_csv, index=False, header=['latency'], sep=delimiter)\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\latency.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\latency_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = latency_pre(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d32bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'latency'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    latency_pre(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc990904",
   "metadata": {},
   "source": [
    "# add header for nf_out csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a836413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = [\"tag\", \"instance_id\", \"service_id\", \"thread_info.core\",\n",
    "              \"rx_pps\",\"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\",\"act_drop\", \"thread_info.parent\",\n",
    "              \"state\", \"rte_atomic16_read\", \n",
    "             \"rx_drop_rate\",\"tx_drop_rate\", \"rx_drop\",\"tx_drop\", \"act_next\", \n",
    "             \"act_buffer\",\"act_returned\"]\n",
    "\n",
    "def nf_out_pre(input_file_path, output_file_path, header):\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "        \n",
    "    with open(output_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data)\n",
    "\n",
    "input_file = f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\nf_out.csv'\n",
    "output_file =f'..\\\\data\\\\pcm\\\\const_input\\\\const-1\\\\nf_out_processed.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = nf_out_pre(input_file, output_file,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b74b1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    exp_ls = f'nf_out'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}.csv'\n",
    "    output_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    nf_out_pre(input_file_path, output_file_path,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dbaf43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_and_merge_rows(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.drop(['instance_id', 'service_id'], axis=1, inplace=True)\n",
    "    tags = ['ndpi_stat', 'router', 'payload_scan', 'bridge', 'firewall']\n",
    "    features = [\"thread_info.core\", \"rx_pps\", \"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\", \"act_drop\", \"thread_info.parent\",\n",
    "                \"state\", \"rte_atomic16_read\", \"rx_drop_rate\", \"tx_drop_rate\", \"rx_drop\", \"tx_drop\", \"act_next\", \n",
    "                \"act_buffer\", \"act_returned\"]\n",
    "    \n",
    "    # new dataframe\n",
    "    new_columns = [f\"{tag}-{feature}\" for tag in tags for feature in features]\n",
    "    new_df = pd.DataFrame(columns=new_columns)\n",
    "    \n",
    "    # fill data\n",
    "    for tag in tags:\n",
    "        tag_df = df[df['tag'] == tag].reset_index(drop=True)\n",
    "        for feature in features:\n",
    "            new_df[f\"{tag}-{feature}\"] = tag_df[feature]\n",
    "    \n",
    "    # save processed data\n",
    "    processed_file_path =  file_path\n",
    "    new_df.to_csv(processed_file_path, index=False)\n",
    "    \n",
    "    return processed_file_path\n",
    "\n",
    "\n",
    "#file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\const-3\\\\nf_out_processed.csv'\n",
    "#process_and_merge_rows(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22c3e9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const-1\n",
      "..\\data\\pcm\\const_input\\const-1\\nf_out_processed.csv\n",
      "const-2\n",
      "..\\data\\pcm\\const_input\\const-2\\nf_out_processed.csv\n",
      "const-3\n",
      "..\\data\\pcm\\const_input\\const-3\\nf_out_processed.csv\n",
      "const-4\n",
      "..\\data\\pcm\\const_input\\const-4\\nf_out_processed.csv\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    print(folder)\n",
    "    exp_ls = f'nf_out'\n",
    "    input_file_path = f'..\\\\data\\\\pcm\\\\const_input\\\\{folder}\\\\{exp_ls}_processed.csv'\n",
    "    process_and_merge_rows(input_file_path)\n",
    "    print(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329dc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
